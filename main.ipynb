{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import re\n",
    "ls =listdir('./20_newsgroups')\n",
    "dict_features = {}\n",
    "for folder in ls:\n",
    "    files=listdir('./20_newsgroups/'+folder)\n",
    "    for file in files:\n",
    "        f=open('./20_newsgroups/'+folder+'/'+file,'r',encoding=\"ISO-8859-1\")\n",
    "        try:\n",
    "            text = f.read()\n",
    "            tokens = re.compile('\\w+').findall(text)\n",
    "            words = [token.lower() for token in tokens if ( token.isalpha() and len(token)>1 and token not in stop_words)]\n",
    "            for word in words:\n",
    "                if word in dict_features:\n",
    "                    dict_features[word]+=1\n",
    "                else:\n",
    "                    dict_features[word]=1\n",
    "        except:\n",
    "            print('Error in reading file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_values = sorted(dict_features.items(), key=operator.itemgetter(1),reverse = True)\n",
    "sorted_dict = dict(sorted_values)\n",
    "features = sorted_dict.keys()\n",
    "selected_features=[]\n",
    "for feature in features:\n",
    "    if feature not in stop_words:\n",
    "        selected_features.append(feature)\n",
    "selected_features=selected_features[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n",
      "Error in reading file\n"
     ]
    }
   ],
   "source": [
    "X_data=[]\n",
    "Y_data=[]\n",
    "for folder in ls:\n",
    "    files=listdir('./20_newsgroups/'+folder)\n",
    "    for file in files:\n",
    "        f=open('./20_newsgroups/'+folder+'/'+file,'r',encoding=\"ISO-8859-1\")\n",
    "        try:\n",
    "            text = f.read()\n",
    "            #tokens = word_tokenize(text)\n",
    "            tokens = re.compile('\\w+').findall(text)\n",
    "            words = [token.lower() for token in tokens if ( token.isalpha() and token not in stop_words and len(token)>1)]\n",
    "            x=[]\n",
    "            for i in range(0,1000):\n",
    "                x.append(0)\n",
    "            Y_data.append(ls.index(folder))\n",
    "            for word in words:\n",
    "                if word in selected_features:\n",
    "                    pos = selected_features.index(word)\n",
    "                    x[pos]+=1\n",
    "            X_data.append(x)\n",
    "        except:\n",
    "            print('Error in reading file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_data,Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "y_predict=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798238590873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def fit(x_train,y_train):\n",
    "    dict_file={}\n",
    "    y_classes=set(y_train)\n",
    "    feature_class=x_train.shape[1]\n",
    "    dict_file['total']=len(y_train)\n",
    "    for y in y_classes:\n",
    "        dict_file[y]={}\n",
    "        dict_file[y]['total_y']=len(y_train[(y_train==y)])\n",
    "        x_features=x_train[y_train==y]\n",
    "        for i in range(1,feature_class+1):\n",
    "            dict_file[y][i]={}\n",
    "            possible_values=set(x_train[:,i-1])\n",
    "            for x in possible_values:\n",
    "                dict_file[y][i][x]=(x_features[:,i-1]==x).sum()     \n",
    "    return dict_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPrediction(x,dict):\n",
    "    y_classes=dict.keys()\n",
    "    class_predicted=-1\n",
    "    max_prob=-1000\n",
    "    for y in y_classes:\n",
    "        if y != 'total':\n",
    "            prob=np.log(dict[y]['total_y'])-np.log(dict['total'])\n",
    "            x_features=dict[y].keys()\n",
    "            i=0\n",
    "            for xf in x_features:\n",
    "                   if xf != 'total_y':\n",
    "                         if x[i] in dict[y][xf].keys():\n",
    "                           prob=prob+np.log(dict[y][xf][x[i]]+1)-np.log(dict[y]['total_y']+len(dict[y][xf]))\n",
    "                         i=i+1\n",
    "            if prob > max_prob:\n",
    "                max_prob=prob\n",
    "                class_predicted=y\n",
    "    return class_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x_test,dict_file):\n",
    "    y_predict=[]\n",
    "    for x in x_test:\n",
    "        y_predict.append(getPrediction(x,dict_file))\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictme=fit(np.array(x_train),np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict=predict(x_test,dictme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927942353883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['line', 'subject', 'newsgroup', 'date', 'organ', 'path', 'apr', 'gmt', 'would', 'write', 'one', 'use', 'refer', 'articl', 'like', 'news', 'get', 'sender', 'univers', 'peopl', 'know', 'think', 'say', 'time', 'system', 'thi', 'make', 'also', 'go', 'may', 'work', 'could', 'new', 'want', 'good', 'right', 'year', 'xref', 'see', 'need', 'even', 'way', 'thing', 'look', 'well', 'problem', 'christian', 'usenet', 'god', 'state', 'uunet', 'distribut', 'mani', 'much', 'tri', 'file', 'first', 'us', 'two', 'comput', 'question', 'max', 'take', 'world', 'call', 'believ', 'window', 'post', 'come', 'point', 'program', 'mean', 'anyon', 'said', 'ca', 'rochest', 'seem', 'run', 'help', 'read', 'differ', 'pleas', 'realli', 'someth', 'find', 'drive', 'number', 'gatech', 'includ', 'sinc', 'back', 'inform', 'thank', 'govern', 'day', 'reason', 'still', 'game', 'give', 'person', 'start', 'case', 'gener', 'support', 'part', 'udel', 'law', 'follow', 'might', 'ask', 'better', 'last', 'sure', 'fact', 'group', 'never', 'let', 'set', 'interest', 'must', 'usa', 'power', 'version', 'without', 'car', 'possibl', 'anoth', 'david', 'imag', 'thu', 'someon', 'got', 'made', 'scienc', 'chang', 'avail', 'key', 'control', 'tell', 'name', 'put', 'lot', 'live', 'list', 'exist', 'word', 'data', 'actual', 'happen', 'opinion', 'space', 'softwar', 'place', 'claim', 'card', 'public', 'john', 'probabl', 'book', 'anyth', 'etc', 'origin', 'littl', 'around', 'howev', 'gun', 'long', 'fri', 'nation', 'kill', 'show', 'usc', 'everi', 'engin', 'consid', 'keep', 'best', 'true', 'bit', 'play', 'object', 'cours', 'tue', 'team', 'least', 'talk', 'user', 'idea', 'order', 'base', 'whi', 'enough', 'messag', 'moral', 'second', 'issu', 'armenian', 'great', 'note', 'servic', 'end', 'provid', 'chip', 'human', 'research', 'technolog', 'sourc', 'though', 'sun', 'jesu', 'exampl', 'either', 'commun', 'respons', 'life', 'noth', 'far', 'requir', 'els', 'mail', 'next', 'answer', 'thought', 'send', 'caus', 'found', 'real', 'ye', 'mark', 'rather', 'free', 'report', 'wrong', 'bill', 'price', 'current', 'effect', 'discuss', 'hard', 'old', 'doe', 'man', 'valu', 'allow', 'quit', 'center', 'machin', 'internet', 'care', 'mon', 'american', 'access', 'standard', 'jew', 'kind', 'view', 'phone', 'sever', 'suggest', 'done', 'disk', 'feel', 'mayb', 'seen', 'hope', 'understand', 'develop', 'email', 'hi', 'address', 'evid', 'abl', 'result', 'yet', 'turn', 'accept', 'buy', 'bad', 'ever', 'sound', 'ani', 'manag', 'hand', 'alway', 'high', 'driver', 'wrote', 'fire', 'author', 'heard', 'applic', 'open', 'type', 'israel', 'whether', 'institut', 'wed', 'forc', 'home', 'children', 'less', 'agre', 'network', 'code', 'three', 'today', 'rememb', 'player', 'given', 'michael', 'area', 'keyword', 'compani', 'away', 'design', 'mac', 'love', 'import', 'test', 'graphic', 'copi', 'color', 'left', 'move', 'presid', 'build', 'big', 'win', 'religion', 'posit', 'encrypt', 'studi', 'matter', 'war', 'countri', 'sale', 'oper', 'depart', 'check', 'unit', 'appear', 'local', 'creat', 'major', 'info', 'cost', 'product', 'display', 'assum', 'paul', 'approv', 'larg', 'pay', 'wupost', 'complet', 'box', 'net', 'argument', 'offic', 'secur', 'perhap', 'format', 'experi', 'wonder', 'frank', 'agat', 'week', 'speed', 'offer', 'rule', 'side', 'guy', 'pc', 'stop', 'mind', 'memori', 'becom', 'steve', 'alreadi', 'protect', 'church', 'hous', 'stuff', 'deal', 'money', 'expect', 'small', 'mike', 'monitor', 'specif', 'death', 'intern', 'close', 'form', 'save', 'bibl', 'statement', 'die', 'mention', 'member', 'present', 'correct', 'polit', 'recent', 'ago', 'act', 'sell', 'came', 'fax', 'robert', 'month', 'whole', 'server', 'packag', 'told', 'model', 'pretti', 'school', 'action', 'process', 'final', 'jim', 'natur', 'truth', 'perform', 'attack', 'light', 'regard', 'rate', 'guess', 'advanc', 'histori', 'receiv', 'board', 'continu', 'instal', 'bodi', 'pass', 'colleg', 'everyon', 'hit', 'except', 'hear', 'fbi', 'often', 'friend', 'speak', 'arm', 'comment', 'homosexu', 'muslim', 'full', 'involv', 'situat', 'simpli', 'plan', 'sort', 'administr', 'everyth', 'limit', 'total', 'rutger', 'head', 'sens', 'usual', 'went', 'canada', 'april', 'citi', 'error', 'almost', 'contact', 'term', 'certainli', 'appl', 'earth', 'carri', 'drug', 'turkish', 'na', 'account', 'activ', 'de', 'suppos', 'caen', 'black', 'appreci', 'clipper', 'return', 'command', 'anyway', 'instead', 'oh', 'explain', 'unix', 'hold', 'video', 'privat', 'white', 'event', 'wo', 'lead', 'level', 'later', 'devic', 'men', 'isra', 'job', 'faith', 'ftp', 'although', 'clear', 'press', 'connect', 'definit', 'basic', 'theori', 'convert', 'bike', 'christ', 'appli', 'quot', 'dept', 'jewish', 'contain', 'belief', 'defin', 'observ', 'function', 'fan', 'site', 'leav', 'unless', 'nice', 'project', 'within', 'scsi', 'document', 'singl', 'ad', 'cover', 'night', 'coupl', 'sat', 'individu', 'weapon', 'text', 'hell', 'physic', 'california', 'busi', 'polic', 'stand', 'period', 'health', 'decid', 'similar', 'page', 'sin', 'concern', 'learn', 'relat', 'attempt', 'ground', 'anybodi', 'summari', 'land', 'express', 'corpor', 'clinton', 'practic', 'arab', 'releas', 'detail', 'road', 'repli', 'hedrick', 'societi', 'record', 'peac', 'atheist', 'mode', 'compar', 'san', 'size', 'watch', 'jame', 'legal', 'field', 'accord', 'brian', 'mine', 'face', 'religi', 'direct', 'ibm', 'especi', 'addit', 'parti', 'figur', 'wait', 'certain', 'stori', 'destroy', 'delet', 'saw', 'simpl', 'begin', 'purpos', 'koresh', 'via', 'took', 'known', 'women', 'describ', 'option', 'ignor', 'dead', 'entir', 'past', 'fine', 'dave', 'exactli', 'top', 'tin', 'special', 'among', 'common', 'electron', 'add', 'million', 'rest', 'divis', 'shot', 'western', 'screen', 'owner', 'sorri', 'taken', 'condit', 'murder', 'polici', 'faq', 'peter', 'goe', 'red', 'request', 'bob', 'normal', 'tax', 'crime', 'replac', 'increas', 'notic', 'print', 'upon', 'insur', 'emori', 'hardwar', 'ga', 'hockey', 'third', 'particular', 'associ', 'absolut', 'whatev', 'written', 'king', 'fast', 'swrind', 'medic', 'fail', 'york', 'sometim', 'therefor', 'per', 'offici', 'low', 'season', 'propos', 'bb', 'output', 'ok', 'paper', 'tape', 'pick', 'port', 'radio', 'cut', 'doubt', 'due', 'burn', 'orbit', 'defens', 'washington', 'goal', 'futur', 'handl', 'serv', 'depend', 'method', 'prefer', 'easi', 'islam', 'feder', 'manual', 'prove', 'remov', 'lie', 'produc', 'lost', 'texa', 'letter', 'earli', 'ame', 'wa', 'ogics', 'flame', 'scott', 'andrew', 'keith', 'front', 'seri', 'prevent', 'miss', 'four', 'short', 'section', 'font', 'ii', 'longer', 'eric', 'chanc', 'dod', 'tool', 'digit', 'algorithm', 'air', 'publish', 'choic', 'young', 'outsid', 'indic', 'librari', 'freedom', 'minor', 'blue', 'ed', 'score', 'announc', 'select', 'break', 'market', 'bu', 'water', 'modem', 'vote', 'educ', 'worth', 'decis', 'hour', 'bring', 'anonym', 'basebal', 'knowledg', 'resourc', 'commit', 'ride', 'ship', 'shall', 'launch', 'constitut', 'plu', 'pat', 'switch', 'variou', 'thoma', 'pittsburgh', 'famili', 'pipex', 'wish', 'leagu', 'disclaim', 'court', 'respect', 'meet', 'jpeg', 'occur', 'fall', 'poster', 'mous', 'charg', 'featur', 'repres', 'logic', 'tom', 'agenc', 'sign', 'technic', 'draw', 'qualiti', 'lab', 'solut', 'popul', 'interpret', 'richard', 'lord', 'smith', 'ha', 'amount', 'behind', 'citizen', 'greek', 'measur', 'directori', 'ram', 'widget', 'toronto', 'none', 'togeth', 'militari', 'voic', 'strong', 'abort', 'higher', 'food', 'entri', 'previou', 'along', 'necessari', 'share', 'adam', 'judg', 'child', 'student', 'remain', 'main', 'search', 'trade', 'nasa', 'father', 'initi', 'pictur', 'bank', 'al', 'fix', 'class', 'fund', 'laboratori', 'la', 'russian', 'near', 'soon', 'fight', 'db', 'chri', 'media', 'crimin', 'fit', 'respond', 'tv', 'minut', 'georg', 'mormon', 'printer', 'load', 'appar', 'suppli', 'doctor', 'interfac', 'armenia', 'jon', 'averag', 'secret', 'imagin', 'sent', 'toward', 'languag', 'clearli', 'genocid', 'mile', 'approach', 'station', 'henri', 'cabl', 'boston', 'hole', 'predict', 'mass', 'uknet', 'age', 'determin', 'son', 'avoid', 'eye', 'anim', 'materi', 'danger', 'decwrl', 'basi', 'door', 'wire', 'america', 'enforc', 'purchas', 'civil', 'drop', 'mission', 'recommend', 'independ', 'otherwis', 'equip', 'stupid', 'angel', 'seriou', 'separ', 'germani', 'stay', 'commerci', 'implement', 'dan', 'ray', 'joe', 'roger', 'happi', 'realiz', 'chicago', 'agent', 'unfortun', 'diseas', 'turk', 'equal', 'late', 'convers', 'waco', 'ide', 'scientif', 'matthew', 'batf', 'bought', 'grant', 'effort', 'north', 'success', 'illinoi', 'spend', 'capabl', 'choos', 'block', 'inde', 'folk', 'vs', 'hate', 'concept', 'neither', 'cdt', 'built', 'argu', 'insid', 'serial', 'reach', 'nois', 'hp', 'lack', 'rais', 'manufactur', 'consist', 'patient', 'illeg', 'necessarili', 'locat', 'torn', 'uk', 'altern', 'obvious', 'rel', 'ny', 'teach', 'heart', 'room', 'street', 'upgrad', 'rang', 'leader', 'confer', 'faster', 'thousand', 'firearm', 'suffer', 'reserv', 'onli', 'obtain', 'gave', 'collect', 'archiv', 'improv', 'directli', 'kid', 'employ', 'intend']\n"
     ]
    }
   ],
   "source": [
    "print(selected_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
